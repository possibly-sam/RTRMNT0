{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "ollama": {
      "npm": "@ai-sdk/openai-compatible",
      "options": {
        "baseURL": "http://localhost:11434/v1"
      },
      "models": {
        "granite3.2:2b": {},
        "starcoder2:7b": {},
        "mistral:7b": {}
      }
    }
  },
  "mcp": {
    "weather": {
      "type": "local",
      "command": ["opencode", "x", "@h1deya/mcp-server-weather"]
    },
    "everything": {
      "type": "local",
      "command": ["opencode", "x", "@modelcontextprotocol/server-everything"]
    }
  }
}
